{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:45.355290Z",
     "start_time": "2024-10-15T19:11:43.937377Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# read the files\n",
    "df_train_file = pd.read_csv('train.csv')\n",
    "df_test_file = pd.read_csv('test.csv')\n",
    "df_col_label = pd.read_csv('codebook.csv')"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:45.385682Z",
     "start_time": "2024-10-15T19:11:45.364229Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# show the info of the train file\n",
    "# df_train_file.info()\n",
    "# df_train_file.head()"
   ],
   "id": "6f0da6b0eca2e73c",
   "outputs": [],
   "execution_count": 36
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:45.400810Z",
     "start_time": "2024-10-15T19:11:45.389798Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# show the info of the test file\n",
    "# df_test_file.info()\n",
    "# df_test_file.head()"
   ],
   "id": "d22b30c5e2efd1a6",
   "outputs": [],
   "execution_count": 37
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:45.745854Z",
     "start_time": "2024-10-15T19:11:45.661314Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# convert the training data and test data into numpy arrays\n",
    "test_data = df_test_file.to_numpy()\n",
    "\n",
    "y = df_train_file['target'].values\n",
    "full_data = df_train_file.drop('target', axis=1)\n",
    "\n",
    "print(f'The proportion of middle class in the training set is {sum(y)/len(y)}')"
   ],
   "id": "5a68dda56c4c0db",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The proportion of middle class in the training set is 0.2102622690244387\n"
     ]
    }
   ],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:18:08.531829Z",
     "start_time": "2024-10-15T19:18:08.439925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the X into continuous and discrete\n",
    "discrete_cols = []\n",
    "binary_cols = []\n",
    "variable_names = df_col_label['Variable Name'].values\n",
    "variable_type = df_col_label['Type'].values\n",
    "\n",
    "mapping = {}\n",
    "states = []\n",
    "for index, name in enumerate(variable_names):\n",
    "    mapping[name] = variable_type[index]\n",
    "    \n",
    "for index, name in enumerate(list(full_data.columns)):\n",
    "    if not name.startswith('state') and mapping[name] != 'continuous':\n",
    "        discrete_cols.append(name)\n",
    "        \n",
    "for i in list(full_data.columns):\n",
    "    if i.startswith('state'):\n",
    "        discrete_cols.append(i)\n",
    "        binary_cols.append(i)\n",
    "\n",
    "df_discrete_test_data = df_test_file[discrete_cols].copy()\n",
    "df_discrete_cols = full_data[discrete_cols].copy()\n",
    "df_continuous_cols = full_data.drop(discrete_cols, axis=1)\n",
    "df_binary_cols = full_data[binary_cols].copy()"
   ],
   "id": "9a4c2c0119b6563c",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:49.729948Z",
     "start_time": "2024-10-15T19:11:49.652321Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is processing for the standardization (no need for binary)\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "continuous_cols_st = scaler.fit_transform(df_continuous_cols)"
   ],
   "id": "333a612d47b1cae4",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:50.704244Z",
     "start_time": "2024-10-15T19:11:50.332060Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# this is PCA\n",
    "from sklearn.decomposition import PCA\n",
    "continuous_cols_st_copy = continuous_cols_st.copy()\n",
    "pca = PCA(n_components=4)\n",
    "continuous_cols_st_pca = pca.fit_transform(continuous_cols_st_copy)"
   ],
   "id": "e21ec254ccefdc5d",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:52.129127Z",
     "start_time": "2024-10-15T19:11:52.002338Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# choose the training data here\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "all_discrete = df_discrete_cols.to_numpy()\n",
    "all_binary = df_binary_cols.to_numpy()\n",
    "all_continuous = df_continuous_cols.to_numpy()\n",
    "all_pca = pd.concat([pd.DataFrame(continuous_cols_st_pca), df_discrete_cols], axis=1).to_numpy()\n",
    "all_binary_pca = pd.concat([pd.DataFrame(continuous_cols_st_pca), df_binary_cols], axis=1).to_numpy()\n",
    "\n",
    "X = all_discrete\n",
    "\n",
    "print((all_discrete.shape[1]))\n",
    "print(all_binary.shape[1])\n",
    "print((all_continuous.shape[1]))\n",
    "print((all_continuous.shape[0]))"
   ],
   "id": "9d781902e5186dc1",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "117\n",
      "40\n",
      "42\n",
      "20132\n"
     ]
    }
   ],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:22:41.898732Z",
     "start_time": "2024-10-15T19:22:41.873921Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# set seed\n",
    "seed = 42"
   ],
   "id": "c42433e92cb1de42",
   "outputs": [],
   "execution_count": 51
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:55.850888Z",
     "start_time": "2024-10-15T19:11:55.757929Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# split the training data into training and validation\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_validation, y_train, y_validation = train_test_split(X, y, test_size=0.2, random_state=seed)"
   ],
   "id": "c018749dd9b997e",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:11:57.964049Z",
     "start_time": "2024-10-15T19:11:57.932090Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# import the accuracy_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# simple dummy classifier\n",
    "from sklearn.dummy import DummyClassifier\n",
    "dummy_clf = DummyClassifier(strategy='most_frequent', random_state=seed)\n",
    "dummy_clf.fit(X_train, y_train)\n",
    "print(dummy_clf.score(X_validation, y_validation))\n",
    "print(f'The percentage of people from middle is {np.average(y)}')"
   ],
   "id": "238352ea80d2a846",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.783213310156444\n",
      "The percentage of people from middle is 0.2102622690244387\n"
     ]
    }
   ],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:12:02.386667Z",
     "start_time": "2024-10-15T19:12:00.149863Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "# from sklearn.svm import SVC too much time (quadratic, better to use linear SVC or SGD)\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import ExtraTreesClassifier # shit: too much time to run and worse results\n",
    "from sklearn.ensemble import GradientBoostingClassifier # shit: too much time to run and worse results\n",
    "from xgboost import XGBClassifier # shit: too much time to run and worse results\n",
    "# from sklearn.naive_bayes import GaussianNB\n",
    "# from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import BernoulliNB # not a good one\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis # shit\n",
    "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis # shit\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import GridSearchCV"
   ],
   "id": "1c477378b1d0c09c",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# logistic regression\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "    'penalty': ['l1', 'l2', 'elasticnet'],\n",
    "    'alpha': [0.001, 0.01, 0.1],\n",
    "    'learning_rate': ['constant', 'optimal', 'adaptive', 'invscaling'],\n",
    "    'eta0': [0.001, 0.01, 0.1],\n",
    "}\n",
    "\n",
    "model = SGDClassifier(\n",
    "    loss='log_loss',\n",
    "    class_weight='balanced',\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")\n"
   ],
   "id": "e71e9a66be2bc35b",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# linear SVC\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "    'penalty': ['l1', 'l2'],\n",
    "    'loss': ['hinge', 'squared_hinge'],\n",
    "    'C': [0.001, 0.01, 0.1, 1],\n",
    "}\n",
    "\n",
    "model = LinearSVC(\n",
    "    class_weight='balanced',\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")\n"
   ],
   "id": "8ea4384111bec3cc",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# KNN\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "    'n_neighbors': [3, 4, 5],\n",
    "    'weights': ['uniform', 'distance'],\n",
    "}\n",
    "\n",
    "model = KNeighborsClassifier(\n",
    "    \n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")\n"
   ],
   "id": "bf11e819d1594eaa",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:23:27.363387Z",
     "start_time": "2024-10-15T19:22:46.834813Z"
    }
   },
   "cell_type": "code",
   "source": [
    "X = all_discrete\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    n_estimators=300,\n",
    "    class_weight='balanced',\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "model.fit(X, y)\n",
    "prediction = model.predict(df_discrete_test_data.to_numpy())\n",
    "\n"
   ],
   "id": "a96d128a6cf57ece",
   "outputs": [],
   "execution_count": 52
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-10-15T19:25:17.570256Z",
     "start_time": "2024-10-15T19:25:17.546114Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(prediction))\n",
    "print(sum(prediction)/len(prediction))\n",
    "print(sum(x for x in prediction if x == 1))"
   ],
   "id": "7f06d14d313ea498",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5034\n",
      "0.17401668653158522\n",
      "876\n"
     ]
    }
   ],
   "execution_count": 53
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# random forest\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "}\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    n_estimators=300,\n",
    "    class_weight='balanced',\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=10, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")"
   ],
   "id": "54e125cdb8a1f27e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = RandomForestClassifier(\n",
    "    bootstrap=True,\n",
    "    criterion='entropy',\n",
    "    n_estimators=300,\n",
    "    class_weight='balanced',\n",
    "    random_state=seed,\n",
    ")\n",
    "model.fit(X, y)\n",
    "model.score(X, y)"
   ],
   "id": "8efd6b4ef7f2fc41",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# extra tree\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'criterion': ['gini', 'entropy', 'log_loss'],\n",
    "    'bootstrap': [True, False],\n",
    "    'oob_score': [True, False],\n",
    "}\n",
    "\n",
    "model = ExtraTreesClassifier(\n",
    "    class_weight='balanced',\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")"
   ],
   "id": "82490a803dbab31e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# gradient boosting\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "    'loss': ['log_loss', 'exponential'],\n",
    "    'learning_rate': [0.001, 0.01, 0.1],\n",
    "    'n_estimators': [300],\n",
    "    'criterion': ['friedman_mse', 'squared_error'],\n",
    "    'max_features': ['sqrt', 'log2', None]\n",
    "}\n",
    "\n",
    "model = GradientBoostingClassifier(\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")"
   ],
   "id": "ebb3b4c7b64fa215",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# xgb\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "    'booster': ['gbtree', 'dart'],\n",
    "    'eta': [0.1, 0.3, 0.5],\n",
    "    'objective': ['binary:logistic', 'binary:logitraw'],\n",
    "}\n",
    "\n",
    "model = XGBClassifier(\n",
    "    seed=seed,\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")"
   ],
   "id": "7bc090f5c058307c",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# Binomial\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "\n",
    "}\n",
    "\n",
    "model = BernoulliNB(\n",
    "    \n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")"
   ],
   "id": "1f1237cb18ce131f",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# linear discriminant\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "    'solver': ['svd', 'lsqr', 'eigen'],\n",
    "    'shrinkage': ['auto', None],\n",
    "}\n",
    "\n",
    "model = LinearDiscriminantAnalysis(\n",
    "    \n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")"
   ],
   "id": "d9bffef32d9f6d61",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# quadratic discriminant\n",
    "X = all_discrete\n",
    "\n",
    "parameters = {\n",
    "\n",
    "}\n",
    "\n",
    "model = QuadraticDiscriminantAnalysis(\n",
    "    \n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")"
   ],
   "id": "51ee5a67b3702a68",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# deep learning\n",
    "X = all_discrete\n",
    "\n",
    "# parameters = {\n",
    "#     'activation': ['logistic', 'relu'],\n",
    "#     'solver': ['lbfgs', 'adam', 'sgd'],\n",
    "#     'batch_size': [32, 64, 128],\n",
    "#     'learning_rate': ['adaptive'],\n",
    "#     'learning_rate_init': [0.0001, 0.001, 0.01],\n",
    "#     'max_iter': [200],\n",
    "#     'hidden_layer_sizes': [(64, 32)],\n",
    "# }\n",
    "\n",
    "parameters = {\n",
    "    'activation': ['relu'],\n",
    "    'solver': ['adam'],\n",
    "    'batch_size': [32],\n",
    "    'learning_rate': ['adaptive'],\n",
    "    'learning_rate_init': [0.001],\n",
    "    'max_iter': [200],\n",
    "    'hidden_layer_sizes': [(64, 32)],\n",
    "}\n",
    "\n",
    "\n",
    "model = MLPClassifier(\n",
    "    random_state=seed,\n",
    ")\n",
    "\n",
    "cv = GridSearchCV(model, parameters, n_jobs=-1, cv=5, scoring={'F1': 'f1', 'Acc': 'accuracy'}, refit='F1')\n",
    "cv.fit(X, y)\n",
    "\n",
    "print(f\"The best F1 score: {cv.best_score_}, the std: {cv.cv_results_['std_test_F1'][cv.best_index_]}\")\n",
    "print(f\"The corresponding acc score: {cv.cv_results_['mean_test_Acc'][cv.best_index_]}, the std: {cv.cv_results_['std_test_Acc'][cv.best_index_]}\")\n",
    "print(f\"The best estimator params: {cv.best_params_}\")"
   ],
   "id": "74a0003eca019687",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model = MLPClassifier(\n",
    "    activation='relu',\n",
    "    solver='adam',\n",
    "    batch_size=32,\n",
    "    learning_rate='adaptive',\n",
    "    learning_rate_init=0.001,\n",
    "    max_iter=1000,\n",
    "    hidden_layer_sizes=(64)\n",
    ")\n",
    "\n",
    "model.fit(X_train,y_train)\n",
    "model.score(X_validation, y_validation)"
   ],
   "id": "db8d8f647ef501",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "a36d76935af655d7",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-07T13:27:50.688380Z",
     "start_time": "2024-11-07T13:27:49.893712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact\n",
    "import ipywidgets as widgets\n",
    "\n",
    "# Define the function to plot the sine wave\n",
    "def plot_sine_wave(frequency):\n",
    "    x = np.linspace(0, 2 * np.pi, 1000)  # X-axis range\n",
    "    y = np.sin(frequency * x)            # Sine wave with variable frequency\n",
    "    \n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.plot(x, y, label=f'Sine wave with frequency {frequency} Hz')\n",
    "    plt.xlabel('X')\n",
    "    plt.ylabel('sin(X)')\n",
    "    plt.title('Sine Wave with Adjustable Frequency')\n",
    "    plt.ylim(-1, 1)\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "\n",
    "# Use ipywidgets' interact function to create a slider\n",
    "interact(plot_sine_wave, frequency=widgets.FloatSlider(value=1, min=0.1, max=10.0, step=0.1));\n"
   ],
   "id": "cd983528a1ab25fe",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "interactive(children=(FloatSlider(value=1.0, description='frequency', max=10.0, min=0.1), Output()), _dom_clas…"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "93d4e7a562984a6ea252fa291e3f840b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "91e575e17fb5512f"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
